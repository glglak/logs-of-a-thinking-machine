---
title: "GLM-5 Just Dropped: The Open Model Crushing Gemini at Half the Price"
pubDatetime: 2026-02-15T07:06:25.882Z
description: "744B params, tops every open benchmark, and costs just $0.80/M tokens—did Z.ai finally crack frontier performance for devs?"
heroImage: "https://example.com/glm5-promo.jpg"
ogImage: "https://example.com/glm5-promo.jpg"
content_pillar: "software"
tags: ["llm","open-source","benchmarks","agents","coding","AI","digest"]
---

![GLM-5 Just Dropped: The Open Model Crushing Gemini at Half the Price](https://example.com/glm5-promo.jpg)

> 744B params, tops every open benchmark, and costs just $0.80/M tokens—did Z.ai finally crack frontier performance for devs?

Imagine firing up a model that matches **Gemini 3 Pro** on coding and agent tasks, but it's fully open-weights and dirt cheap. That's GLM-5, launched February 11 by Z.ai, and it's resetting expectations for what open models can do.

Z.ai dropped GLM-5 with a staggering **744 billion parameters (40B active)**, pre-trained on 28.5 trillion tokens. It hit the top spot on Artificial Analysis' Intelligence Index at **50**—the first open model to do so—while leading coding benchmarks and agentic workflows. Available now on OpenRouter at **$0.80 per million input tokens**, it's not just hype; devs are already swapping it into production pipelines.[1][9]

For developers, this is huge: agentic tasks (think multi-step reasoning or tool use) now run on open models without the proprietary lock-in. No more begging for API access limits or paying premium for marginal gains—GLM-5 delivers **enterprise-grade coding** that beats closed rivals in speed and cost. Your next RAG app or code assistant just got 10x more viable.

Compare it to the field: DeepSeek V3.2 trails on math (93.1% vs GLM-4.7's 95.7% AIME), and proprietary like GPT-5 still edge out on PhD science by 4-5%. But GLM-5's **MoE efficiency** and agent focus make it the practical winner for most workflows, especially multilingual dev teams.[3][9]

Grab it on OpenRouter today and benchmark against your stack—what if this finally makes closed models obsolete? Watch for fine-tunes; community swarms could push it even further.

**Source:** [AIxFunda Substack](https://aixfunda.substack.com/p/top-llm-rag-and-agent-updates-of-03a)
