---
title: "AlphaEvolve & TTT-Discover: LLMs That Invent New Algorithms Overnight"
pubDatetime: 2026-02-08T07:06:27.494Z
description: "LLMs aren't just regurgitating—they're evolving provably better math proofs and GPU kernels. Auto-discovery just went general-purpose."
heroImage: "https://example.com/alphaevolve.jpg"
ogImage: "https://example.com/alphaevolve.jpg"
content_pillar: "research"
tags: ["research","discovery","algorithms","llm","optimization","AI","digest"]
---

![AlphaEvolve & TTT-Discover: LLMs That Invent New Algorithms Overnight](https://example.com/alphaevolve.jpg)

> LLMs aren't just regurgitating—they're evolving provably better math proofs and GPU kernels. Auto-discovery just went general-purpose.

**What if instead of prompting LLMs for code, they *discovered* entirely new algorithms better than human SOTA?** That's no longer sci-fi.

Enter knowledge-creating LLMs like AlphaEvolve (Novikov et al., 2025) and TTT-Discover (Yuksekgonul et al., 2026). These are general methods turning LLMs into optimization engines for *any* problem: they evolve novel, provably correct algorithms in math, CS, GPU kernels (2x faster), biology denoising, and more—surpassing prior specialized AI like AlphaFold.[1]

Devs, this supercharges your stack: auto-optimize models, invent better schedulers/codecs, or craft trading algos. Unlike narrow tools, these adapt quickly to your domain, slashing R&D cycles from months to hours.

AlphaFold was protein-specific; these are universal, generalizing across maths (Erdős problems), AtCoder contests, and single-cell bio. TTT-Discover SOTA'd nearly every benchmark it touched, verified by experts. The shift from 'AI assists' to 'AI invents' rewires the ecosystem.[1]

Check the papers, replicate on toy optimizations, or build verifiers for your use case. Imagine deploying self-improving agents—what breakthroughs will *you* unlock first?

**Source:** [tecunningham.github.io](https://tecunningham.github.io/posts/2026-01-29-knowledge-creating-llms.html)
