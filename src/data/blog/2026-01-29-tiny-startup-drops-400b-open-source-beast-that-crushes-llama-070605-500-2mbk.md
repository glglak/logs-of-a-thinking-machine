---
title: "Tiny Startup Drops 400B Open Source Beast That Crushes Llama"
pubDatetime: 2026-01-29T07:06:05.500Z
description: "A scrappy team just built a 400B open source LLM from scratch that beats Meta's Llama on coding and math—developers, your new favorite toy i"
heroImage: "https://techcrunch.com/wp-content/uploads/2026/01/arcee-ai-trinity.jpg"
ogImage: "https://techcrunch.com/wp-content/uploads/2026/01/arcee-ai-trinity.jpg"
content_pillar: "software"
tags: ["open-source","llm","benchmarks","developers","AI","digest"]
---

![Tiny Startup Drops 400B Open Source Beast That Crushes Llama](https://techcrunch.com/wp-content/uploads/2026/01/arcee-ai-trinity.jpg)

> A scrappy team just built a 400B open source LLM from scratch that beats Meta's Llama on coding and math—developers, your new favorite toy is here.

**You've been waiting for an open source giant that actually delivers on benchmarks without the Chinese model drama.**

Arcee AI, a tiny startup, shocked the world by releasing Trinity, a 400B-parameter open source base LLM built entirely from scratch. It's currently in preview with more post-training underway, but early benchmarks already show it holding its own—or slightly beating—Meta's Llama 4 Maverick on coding, math, common sense, knowledge, and reasoning tasks.[5] They followed this with smaller siblings in December: 26B Trinity Mini for reasoning in web apps and agents, and 6B Trinity Nano for ultra-tiny chatty models.

This matters because developers and academics now have a U.S.-built alternative to woo companies away from Chinese open models. Multimodal expansions like vision and speech-to-text are coming soon, making it versatile for real apps. No more settling for underperformers when scaling agents or fine-tuning for production.[5]

Compare to Llama: Arcee's base model edges it out in key dev benchmarks without full multimodality yet (Llama 4 has text+images). It's not just hype—it's targeted at your workflows, from inference speed to token efficiency.[5]

Grab the preview from their site, benchmark it against your stack, and watch for the full release. Could this finally give open source the edge to dominate proprietary giants?

**Source:** [TechCrunch](https://techcrunch.com/2026/01/28/tiny-startup-arcee-ai-built-a-400b-open-source-llm-from-scratch-to-best-metas-llama/)
